{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Users used for training:  [ 5  6  7 11 14 16 17 21 22 23 26 28 29 30]\n",
      "Users used for validation:  [ 1 27 25  3 15  8 19]\n"
     ]
    }
   ],
   "source": [
    "from data_helper import timeserie2image, read_files, preprocess_data, timeseries2imageRP\n",
    "train_data, train_y, validation_data, validation_y, test_data, test_y = read_files()\n",
    "test_x = preprocess_data(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: title={'center': 'Count (target)'}, xlabel='0'>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_y.value_counts().plot(kind='bar', title='Count (target)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dpalo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\lightning\\pytorch\\utilities\\migration\\utils.py:56: The loaded checkpoint was produced with Lightning v2.2.4, which is newer than your current Lightning version: v2.2.1\n"
     ]
    }
   ],
   "source": [
    "from data_helper import timeserie2image, read_files, preprocess_data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from dataset import UCIHARDataset\n",
    "from transform import Transform, ResizeTransform\n",
    "import torch\n",
    "from barlowtwins import BarlowTwins\n",
    "from lightning.pytorch.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from lightning.pytorch.trainer import Trainer\n",
    "import datetime\n",
    "import os\n",
    "from classifier import SSLClassifier\n",
    "from torch import nn, set_float32_matmul_precision\n",
    "from torchvision.transforms import ToPILImage, Resize\n",
    "\n",
    "set_float32_matmul_precision('medium')\n",
    "np.random.seed(42)\n",
    "\n",
    "# def main(args):\n",
    "prediction_head = nn.Sequential(\n",
    "    # From (512,1,1) to (512)\n",
    "    # nn.Flatten(),\n",
    "    nn.Linear(512, 256),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(256, 6)\n",
    ")\n",
    "\n",
    "model = BarlowTwins.load_from_checkpoint(f'TRY1/BT-PRETEXT-model.ckpt')\n",
    "classifier = SSLClassifier.load_from_checkpoint(\n",
    "    f'TRY1/BT-DOWNSTREAM-model.ckpt',\n",
    "    backbone=model.backbone,\n",
    "    prediction_head=prediction_head, freeze_backbone=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_helper import timeserie2image, read_files, preprocess_data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from dataset import UCIHARDataset\n",
    "from transform import Transform, ResizeTransform\n",
    "import torch\n",
    "from barlowtwins import BarlowTwins\n",
    "from lightning.pytorch.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from lightning.pytorch.trainer import Trainer\n",
    "import datetime\n",
    "import os\n",
    "from classifier import SSLClassifier\n",
    "from torch import nn, set_float32_matmul_precision\n",
    "from torchvision.transforms import ToPILImage, Resize\n",
    "\n",
    "set_float32_matmul_precision('medium')\n",
    "np.random.seed(42)\n",
    "\n",
    "def main(args):\n",
    "    prediction_head = nn.Sequential(\n",
    "        # From (512,1,1) to (512)\n",
    "        # nn.Flatten(),\n",
    "        nn.Linear(512, 256),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(256, 6)\n",
    "    )\n",
    "    \n",
    "    model = BarlowTwins.load_from_checkpoint(f'{args.dirpath}/BT-PRETEXT-{args.filename}.ckpt')\n",
    "    classifier = SSLClassifier.load_from_checkpoint(\n",
    "        f'TRY1/BT-DOWNSTREAM-model.ckpt',\n",
    "        # backbone=model.backbone,\n",
    "        # prediction_head=prediction_head, freeze_backbone=True\n",
    "        )\n",
    "    classifier = SSLClassifier(backbone=model.backbone, prediction_head=prediction_head, freeze_backbone=True)\n",
    "\n",
    "    model = BarlowTwins.load_from_checkpoint(f'{model_folder}/model.ckpt')\n",
    "    classifier = SSLClassifier(backbone=model.backbone, prediction_head=prediction_head, freeze_backbone=True)\n",
    "\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "train_data, train_y, validation_data, validation_y, test_data, test_y = read_files()\n",
    "test_x = preprocess_data(test_data)\n",
    "\n",
    "test_dataset = UCIHARDataset(test_x, test_y, transform=ResizeTransform(), output_num=1)\n",
    "\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=256, shuffle=False)\n",
    "\n",
    "classifier = SSLClassifier.load_from_checkpoint(f'{model_folder}TEST/model.ckpt', backbone=model.backbone, prediction_head=prediction_head, freeze_backbone=True)\n",
    "# classifier = SSLClassifier(backbone=model.backbone, prediction_head=prediction_head, freeze_backbone=True)\n",
    "\n",
    "trainer = Trainer(accelerator=\"gpu\", devices=[0])\n",
    "# trainer.fit(model=classifier, train_dataloaders=train_dataloader, val_dataloaders=val_dataloader)\n",
    "\n",
    "predictions = trainer.predict(model=classifier, dataloaders=test_dataloader, return_predictions=True)\n",
    "y_orig = []\n",
    "y_pred = []\n",
    "for pred_list in predictions:\n",
    "    y_orig.extend(pred_list[1].tolist())\n",
    "    y_pred.extend(pred_list[0].tolist())\n",
    "\n",
    "from torchmetrics.classification import MulticlassConfusionMatrix\n",
    "target = torch.tensor(y_orig)\n",
    "preds = torch.tensor(y_pred)\n",
    "metric = MulticlassConfusionMatrix(num_classes=6)\n",
    "print(metric(preds, target))\n",
    "\n",
    "\n",
    "# print(torch.stack(predictions).shape)\n",
    "# y_orig = [val[1] for val in predictions]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_helper import timeserie2image, read_files\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from dataset import UCIHARDataset\n",
    "from transform import Transform\n",
    "import torch\n",
    "from barlowtwins import BarlowTwins\n",
    "from lightning.pytorch.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from lightning.pytorch.trainer import Trainer\n",
    "import datetime\n",
    "\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, train_y, validation_data, validation_y, test_data, test_y = read_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "\n",
    "train_x = []\n",
    "for i in range(train_data.shape[0]):\n",
    "    signal = train_data.iloc[i,:].values.reshape(9, -1)\n",
    "    image = timeserie2image(signal)\n",
    "    image = np.array([image, image, image])\n",
    "    image = torch.tensor(image)\n",
    "    image = transforms.ToPILImage()(image)\n",
    "    image = transforms.Resize((224, 224))(image)\n",
    "    # image = transforms.ToTensor()(image)\n",
    "    train_x.append(image)\n",
    "# train_x = torch.stack(train_x)\n",
    "# train_x = torch.tensor(np.array(train_x))\n",
    "\n",
    "validation_x = []\n",
    "for i in range(validation_data.shape[0]):\n",
    "    signal = validation_data.iloc[i,:].values.reshape(9, -1)\n",
    "    image = timeserie2image(signal)\n",
    "    image = np.array([image, image, image])\n",
    "    validation_x.append(image)\n",
    "validation_x = torch\n",
    "# validation_x = torch.tensor(np.array(validation_x))\n",
    "\n",
    "test_x = []\n",
    "for i in range(test_data.shape[0]):\n",
    "    signal = test_data.iloc[i,:].values.reshape(9, -1)\n",
    "    image = timeserie2image(signal)\n",
    "    image = np.array([image, image, image])\n",
    "    test_x.append(image)\n",
    "test_x = torch.tensor(np.array(test_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mtrain_x\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m, validation_x\u001b[38;5;241m.\u001b[39mshape, test_x\u001b[38;5;241m.\u001b[39mshape)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "print(train_x.shape, validation_x.shape, test_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = UCIHARDataset(train_x, train_y, transform=Transform())\n",
    "# val_dataset = UCIHARDataset(validation_x, validation_y, transform=Transform())\n",
    "# test_dataset = UCIHARDataset(test_x, test_y, transform=Transform())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterv = iter(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iterv)[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=256, shuffle=True)\n",
    "val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=256, shuffle=False)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=256, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bt_model = BarlowTwins()\n",
    "current_date = datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer(limit_train_batches=1.0)` was configured so 100% of the batches per epoch will be used..\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\lightning\\pytorch\\trainer\\call.py:44\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[1;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher\u001b[38;5;241m.\u001b[39mlaunch(trainer_fn, \u001b[38;5;241m*\u001b[39margs, trainer\u001b[38;5;241m=\u001b[39mtrainer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m---> 44\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\lightning\\pytorch\\trainer\\trainer.py:580\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[1;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[0;32m    574\u001b[0m ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39m_select_ckpt_path(\n\u001b[0;32m    575\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn,\n\u001b[0;32m    576\u001b[0m     ckpt_path,\n\u001b[0;32m    577\u001b[0m     model_provided\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    578\u001b[0m     model_connected\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    579\u001b[0m )\n\u001b[1;32m--> 580\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    582\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstopped\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\lightning\\pytorch\\trainer\\trainer.py:963\u001b[0m, in \u001b[0;36mTrainer._run\u001b[1;34m(self, model, ckpt_path)\u001b[0m\n\u001b[0;32m    962\u001b[0m \u001b[38;5;66;03m# strategy will configure model and move it to the device\u001b[39;00m\n\u001b[1;32m--> 963\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrategy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msetup\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    965\u001b[0m \u001b[38;5;66;03m# hook\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\lightning\\pytorch\\strategies\\strategy.py:149\u001b[0m, in \u001b[0;36mStrategy.setup\u001b[1;34m(self, trainer)\u001b[0m\n\u001b[0;32m    148\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 149\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maccelerator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msetup\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\lightning\\pytorch\\accelerators\\cuda.py:53\u001b[0m, in \u001b[0;36mCUDAAccelerator.setup\u001b[1;34m(self, trainer)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_nvidia_flags(trainer\u001b[38;5;241m.\u001b[39mlocal_rank)\n\u001b[1;32m---> 53\u001b[0m \u001b[43m_clear_cuda_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\lightning\\fabric\\accelerators\\cuda.py:381\u001b[0m, in \u001b[0;36m_clear_cuda_memory\u001b[1;34m()\u001b[0m\n\u001b[0;32m    380\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_cuda_clearCublasWorkspaces()\n\u001b[1;32m--> 381\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mempty_cache\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\cuda\\memory.py:162\u001b[0m, in \u001b[0;36mempty_cache\u001b[1;34m()\u001b[0m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_initialized():\n\u001b[1;32m--> 162\u001b[0m     \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cuda_emptyCache\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 10\u001b[0m\n\u001b[0;32m      2\u001b[0m checkpoint_callback \u001b[38;5;241m=\u001b[39m ModelCheckpoint(\n\u001b[0;32m      3\u001b[0m     monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m,  \u001b[38;5;66;03m# Monitor validation loss\u001b[39;00m\n\u001b[0;32m      4\u001b[0m     mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin\u001b[39m\u001b[38;5;124m'\u001b[39m,          \u001b[38;5;66;03m# 'min' mode means the checkpoint will be saved when the monitored quantity decreases\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      7\u001b[0m     filename\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m,  \u001b[38;5;66;03m# Filename format\u001b[39;00m\n\u001b[0;32m      8\u001b[0m )\n\u001b[0;32m      9\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(limit_train_batches\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m, max_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100000\u001b[39m, callbacks\u001b[38;5;241m=\u001b[39m[early_stopping, checkpoint_callback], accelerator\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpu\u001b[39m\u001b[38;5;124m\"\u001b[39m, devices\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 10\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbt_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_dataloader\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\lightning\\pytorch\\trainer\\trainer.py:544\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[1;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[0;32m    542\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m=\u001b[39m TrainerStatus\u001b[38;5;241m.\u001b[39mRUNNING\n\u001b[0;32m    543\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 544\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    545\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[0;32m    546\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\lightning\\pytorch\\trainer\\call.py:68\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[1;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m logger \u001b[38;5;129;01min\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mloggers:\n\u001b[0;32m     67\u001b[0m     logger\u001b[38;5;241m.\u001b[39mfinalize(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfailed\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 68\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_teardown\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;66;03m# teardown might access the stage so we reset it after\u001b[39;00m\n\u001b[0;32m     70\u001b[0m trainer\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstage \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\lightning\\pytorch\\trainer\\trainer.py:1010\u001b[0m, in \u001b[0;36mTrainer._teardown\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1007\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_teardown\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1008\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"This is the Trainer's internal teardown, unrelated to the `teardown` hooks in LightningModule and Callback;\u001b[39;00m\n\u001b[0;32m   1009\u001b[0m \u001b[38;5;124;03m    those are handled by :meth:`_call_teardown_hook`.\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1010\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrategy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mteardown\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1011\u001b[0m     loop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_active_loop\n\u001b[0;32m   1012\u001b[0m     \u001b[38;5;66;03m# loop should never be `None` here but it can because we don't know the trainer stage with `ddp_spawn`\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\lightning\\pytorch\\strategies\\strategy.py:540\u001b[0m, in \u001b[0;36mStrategy.teardown\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    538\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprecision_plugin\u001b[38;5;241m.\u001b[39mteardown()\n\u001b[0;32m    539\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 540\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maccelerator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mteardown\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    541\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheckpoint_io\u001b[38;5;241m.\u001b[39mteardown()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\lightning\\pytorch\\accelerators\\cuda.py:82\u001b[0m, in \u001b[0;36mCUDAAccelerator.teardown\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[0;32m     81\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mteardown\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 82\u001b[0m     \u001b[43m_clear_cuda_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\lightning\\fabric\\accelerators\\cuda.py:381\u001b[0m, in \u001b[0;36m_clear_cuda_memory\u001b[1;34m()\u001b[0m\n\u001b[0;32m    378\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _TORCH_GREATER_EQUAL_2_0 \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(torch\u001b[38;5;241m.\u001b[39m_C, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_cuda_clearCublasWorkspaces\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    379\u001b[0m     \u001b[38;5;66;03m# https://github.com/pytorch/pytorch/issues/95668\u001b[39;00m\n\u001b[0;32m    380\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_cuda_clearCublasWorkspaces()\n\u001b[1;32m--> 381\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mempty_cache\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\cuda\\memory.py:162\u001b[0m, in \u001b[0;36mempty_cache\u001b[1;34m()\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Release all unoccupied cached memory currently held by the caching\u001b[39;00m\n\u001b[0;32m    152\u001b[0m \u001b[38;5;124;03mallocator so that those can be used in other GPU application and visible in\u001b[39;00m\n\u001b[0;32m    153\u001b[0m \u001b[38;5;124;03m`nvidia-smi`.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    159\u001b[0m \u001b[38;5;124;03m    more details about GPU memory management.\u001b[39;00m\n\u001b[0;32m    160\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_initialized():\n\u001b[1;32m--> 162\u001b[0m     \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cuda_emptyCache\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "early_stopping = EarlyStopping('val_loss', patience=100, verbose=True, mode='min')\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor='val_loss',  # Monitor validation loss\n",
    "    mode='min',          # 'min' mode means the checkpoint will be saved when the monitored quantity decreases\n",
    "    save_top_k=1,        # Save the best model\n",
    "    dirpath=current_date,  # Directory to save the checkpoints\n",
    "    filename='model',  # Filename format\n",
    ")\n",
    "trainer = Trainer(limit_train_batches=1.0, max_epochs=100000, callbacks=[early_stopping, checkpoint_callback], accelerator=\"gpu\", devices=\"auto\")\n",
    "trainer.fit(model=bt_model, train_dataloaders=train_dataloader, val_dataloaders=val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "base_dir = 'data/UCIHAR/dataset/UCI HAR Dataset'\n",
    "# Training data\n",
    "# Train users\n",
    "train_users = pd.read_csv(f'{base_dir}/train/subject_train.txt', header=None)\n",
    "# Train accelerometer data\n",
    "train_acc_x = pd.read_csv(f'{base_dir}/train/Inertial Signals/body_acc_x_train.txt', delim_whitespace=True, header=None)\n",
    "train_acc_y = pd.read_csv(f'{base_dir}/train/Inertial Signals/body_acc_y_train.txt', delim_whitespace=True, header=None)\n",
    "train_acc_z = pd.read_csv(f'{base_dir}/train/Inertial Signals/body_acc_z_train.txt', delim_whitespace=True, header=None)\n",
    "# Train gyroscope data\n",
    "train_gyro_x = pd.read_csv(f'{base_dir}/train/Inertial Signals/body_gyro_x_train.txt', delim_whitespace=True, header=None)\n",
    "train_gyro_y = pd.read_csv(f'{base_dir}/train/Inertial Signals/body_gyro_y_train.txt', delim_whitespace=True, header=None)\n",
    "train_gyro_z = pd.read_csv(f'{base_dir}/train/Inertial Signals/body_gyro_z_train.txt', delim_whitespace=True, header=None)\n",
    "# Train total acc data\n",
    "train_total_acc_x = pd.read_csv(f'{base_dir}/train/Inertial Signals/total_acc_x_train.txt', delim_whitespace=True, header=None)\n",
    "train_total_acc_y = pd.read_csv(f'{base_dir}/train/Inertial Signals/total_acc_y_train.txt', delim_whitespace=True, header=None)\n",
    "train_total_acc_z = pd.read_csv(f'{base_dir}/train/Inertial Signals/total_acc_z_train.txt', delim_whitespace=True, header=None)\n",
    "\n",
    "# Train labels\n",
    "train_y = pd.read_csv(f'{base_dir}/train/y_train.txt', header=None)\n",
    "\n",
    "# Test data\n",
    "# Test users\n",
    "test_users = pd.read_csv(f'{base_dir}/test/subject_test.txt', header=None)\n",
    "# Test accelerometer data\n",
    "test_acc_x = pd.read_csv(f'{base_dir}/test/Inertial Signals/body_acc_x_test.txt', delim_whitespace=True, header=None)\n",
    "test_acc_y = pd.read_csv(f'{base_dir}/test/Inertial Signals/body_acc_y_test.txt', delim_whitespace=True, header=None)\n",
    "test_acc_z = pd.read_csv(f'{base_dir}/test/Inertial Signals/body_acc_z_test.txt', delim_whitespace=True, header=None)\n",
    "# Test gyroscope data\n",
    "test_gyro_x = pd.read_csv(f'{base_dir}/test/Inertial Signals/body_gyro_x_test.txt', delim_whitespace=True, header=None)\n",
    "test_gyro_y = pd.read_csv(f'{base_dir}/test/Inertial Signals/body_gyro_y_test.txt', delim_whitespace=True, header=None)\n",
    "test_gyro_z = pd.read_csv(f'{base_dir}/test/Inertial Signals/body_gyro_z_test.txt', delim_whitespace=True, header=None)\n",
    "# Test total acc data\n",
    "test_total_acc_x = pd.read_csv(f'{base_dir}/test/Inertial Signals/total_acc_x_test.txt', delim_whitespace=True, header=None)\n",
    "test_total_acc_y = pd.read_csv(f'{base_dir}/test/Inertial Signals/total_acc_y_test.txt', delim_whitespace=True, header=None)\n",
    "test_total_acc_z = pd.read_csv(f'{base_dir}/test/Inertial Signals/total_acc_z_test.txt', delim_whitespace=True, header=None)\n",
    "# Test labels\n",
    "test_y = pd.read_csv(f'{base_dir}/test/y_test.txt', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.concat([train_users, train_gyro_x, train_gyro_y, train_gyro_z, train_total_acc_x, train_total_acc_y, train_total_acc_z, train_acc_x, train_acc_y, train_acc_z], axis=1)\n",
    "test_data = pd.concat([test_users, test_gyro_x, test_gyro_y, test_gyro_z, test_total_acc_x, test_total_acc_y, test_total_acc_z, test_acc_x, test_acc_y, test_acc_z], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7352, 1), (2947, 1), (7352, 1153), (2947, 1153))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_users.shape, test_users.shape, train_data.shape, test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 68)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_elem = train_data.iloc[0,1:]\n",
    "first_elem = first_elem.values.reshape(9, -1)\n",
    "first_elem[:,:68].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1 27 25  3 15  8 19] [ 5  6  7 11 14 16 17 21 22 23 26 28 29 30]\n"
     ]
    }
   ],
   "source": [
    "users_for_train = np.random.choice(train_users.iloc[:,0].unique(), 7, replace=False)\n",
    "users_for_validation = np.setdiff1d(train_users.iloc[:,0].unique(), users_for_train)\n",
    "print(users_for_train, users_for_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dpalo\\AppData\\Local\\Temp\\ipykernel_26204\\3781707170.py:2: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  validation_y = train_y[train_data.iloc[:,0].isin(users_for_validation)]\n"
     ]
    }
   ],
   "source": [
    "train_y = train_y[train_data.iloc[:,0].isin(users_for_train)]\n",
    "validation_y = train_y[train_data.iloc[:,0].isin(users_for_validation)]\n",
    "\n",
    "validation_data = train_data[train_data.iloc[:,0].isin(users_for_validation)].iloc[:,1:]\n",
    "train_data = train_data[train_data.iloc[:,0].isin(users_for_train)].iloc[:,1:]\n",
    "test_data = test_data.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = []\n",
    "for i in range(train_data.shape[0]):\n",
    "    signal = train_data.iloc[i,:].values.reshape(9, -1)\n",
    "    image = timeserie2image(signal)\n",
    "    image = np.array([image, image, image])\n",
    "    train_x.append(image)\n",
    "train_x = torch.tensor(np.array(train_x))\n",
    "\n",
    "validation_x = []\n",
    "for i in range(validation_data.shape[0]):\n",
    "    signal = validation_data.iloc[i,:].values.reshape(9, -1)\n",
    "    image = timeserie2image(signal)\n",
    "    image = np.array([image, image, image])\n",
    "    validation_x.append(image)\n",
    "validation_x = torch.tensor(np.array(validation_x))\n",
    "\n",
    "test_x = []\n",
    "for i in range(test_data.shape[0]):\n",
    "    signal = test_data.iloc[i,:].values.reshape(9, -1)\n",
    "    image = timeserie2image(signal)\n",
    "    image = np.array([image, image, image])\n",
    "    test_x.append(image)\n",
    "test_x = torch.tensor(np.array(test_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2442, 3, 36, 128]),\n",
       " torch.Size([4910, 3, 36, 128]),\n",
       " torch.Size([2947, 3, 36, 128]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape, validation_x.shape, test_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAMPLE SHAPE torch.Size([3, 36, 128])\n"
     ]
    }
   ],
   "source": [
    "train_dataset = UCIHARDataset(train_x, train_y, transform=Transform())\n",
    "val_dataset = UCIHARDataset(validation_x, validation_y, transform=Transform())\n",
    "test_dataset = UCIHARDataset(test_x, test_y, transform=Transform())\n",
    "nextval = next(iter(train_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y.iloc[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 224, 224]), torch.Size([3, 224, 224]), 5)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nextval[0].shape, nextval[1].shape, nextval[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAMPLE SHAPE torch.Size([3, 36, 128])\n",
      "torch.Size([3, 224, 224]) torch.Size([3, 224, 224]) 5\n",
      "SAMPLE SHAPE torch.Size([3, 36, 128])\n",
      "torch.Size([3, 224, 224]) torch.Size([3, 224, 224]) 5\n",
      "SAMPLE SHAPE torch.Size([3, 36, 128])\n",
      "torch.Size([3, 224, 224]) torch.Size([3, 224, 224]) 5\n",
      "SAMPLE SHAPE torch.Size([3, 36, 128])\n",
      "torch.Size([3, 224, 224]) torch.Size([3, 224, 224]) 5\n",
      "SAMPLE SHAPE torch.Size([3, 36, 128])\n",
      "torch.Size([3, 224, 224]) torch.Size([3, 224, 224]) 5\n",
      "SAMPLE SHAPE torch.Size([3, 36, 128])\n",
      "torch.Size([3, 224, 224]) torch.Size([3, 224, 224]) 5\n",
      "SAMPLE SHAPE torch.Size([3, 36, 128])\n",
      "torch.Size([3, 224, 224]) torch.Size([3, 224, 224]) 5\n",
      "SAMPLE SHAPE torch.Size([3, 36, 128])\n",
      "torch.Size([3, 224, 224]) torch.Size([3, 224, 224]) 5\n",
      "SAMPLE SHAPE torch.Size([3, 36, 128])\n",
      "torch.Size([3, 224, 224]) torch.Size([3, 224, 224]) 5\n",
      "SAMPLE SHAPE torch.Size([3, 36, 128])\n",
      "torch.Size([3, 224, 224]) torch.Size([3, 224, 224]) 5\n",
      "SAMPLE SHAPE torch.Size([3, 36, 128])\n",
      "torch.Size([3, 224, 224]) torch.Size([3, 224, 224]) 5\n",
      "SAMPLE SHAPE torch.Size([3, 36, 128])\n",
      "torch.Size([3, 224, 224]) torch.Size([3, 224, 224]) 5\n",
      "SAMPLE SHAPE torch.Size([3, 36, 128])\n",
      "torch.Size([3, 224, 224]) torch.Size([3, 224, 224]) 5\n",
      "SAMPLE SHAPE torch.Size([3, 36, 128])\n",
      "torch.Size([3, 224, 224]) torch.Size([3, 224, 224]) 5\n",
      "SAMPLE SHAPE torch.Size([3, 36, 128])\n",
      "torch.Size([3, 224, 224]) torch.Size([3, 224, 224]) 5\n",
      "SAMPLE SHAPE torch.Size([3, 36, 128])\n",
      "torch.Size([3, 224, 224]) torch.Size([3, 224, 224]) 5\n",
      "SAMPLE SHAPE torch.Size([3, 36, 128])\n",
      "torch.Size([3, 224, 224]) torch.Size([3, 224, 224]) 5\n",
      "SAMPLE SHAPE torch.Size([3, 36, 128])\n",
      "torch.Size([3, 224, 224]) torch.Size([3, 224, 224]) 5\n",
      "SAMPLE SHAPE torch.Size([3, 36, 128])\n",
      "torch.Size([3, 224, 224]) torch.Size([3, 224, 224]) 5\n",
      "SAMPLE SHAPE torch.Size([3, 36, 128])\n",
      "torch.Size([3, 224, 224]) torch.Size([3, 224, 224]) 5\n",
      "SAMPLE SHAPE torch.Size([3, 36, 128])\n",
      "torch.Size([3, 224, 224]) torch.Size([3, 224, 224]) 5\n",
      "SAMPLE SHAPE torch.Size([3, 36, 128])\n",
      "torch.Size([3, 224, 224]) torch.Size([3, 224, 224]) 5\n",
      "SAMPLE SHAPE torch.Size([3, 36, 128])\n",
      "torch.Size([3, 224, 224]) torch.Size([3, 224, 224]) 5\n",
      "SAMPLE SHAPE torch.Size([3, 36, 128])\n",
      "torch.Size([3, 224, 224]) torch.Size([3, 224, 224]) 5\n",
      "SAMPLE SHAPE torch.Size([3, 36, 128])\n",
      "torch.Size([3, 224, 224]) torch.Size([3, 224, 224]) 5\n",
      "SAMPLE SHAPE torch.Size([3, 36, 128])\n",
      "torch.Size([3, 224, 224]) torch.Size([3, 224, 224]) 5\n",
      "SAMPLE SHAPE torch.Size([3, 36, 128])\n",
      "torch.Size([3, 224, 224]) torch.Size([3, 224, 224]) 5\n",
      "SAMPLE SHAPE torch.Size([3, 36, 128])\n",
      "torch.Size([3, 224, 224]) torch.Size([3, 224, 224]) 4\n",
      "SAMPLE SHAPE torch.Size([3, 36, 128])\n",
      "torch.Size([3, 224, 224]) torch.Size([3, 224, 224]) 4\n",
      "SAMPLE SHAPE torch.Size([3, 36, 128])\n",
      "torch.Size([3, 224, 224]) torch.Size([3, 224, 224]) 4\n",
      "SAMPLE SHAPE torch.Size([3, 36, 128])\n",
      "torch.Size([3, 224, 224]) torch.Size([3, 224, 224]) 4\n",
      "SAMPLE SHAPE torch.Size([3, 36, 128])\n",
      "torch.Size([3, 224, 224]) torch.Size([3, 224, 224]) 4\n",
      "SAMPLE SHAPE torch.Size([3, 36, 128])\n",
      "torch.Size([3, 224, 224]) torch.Size([3, 224, 224]) 4\n",
      "SAMPLE SHAPE torch.Size([3, 36, 128])\n",
      "torch.Size([3, 224, 224]) torch.Size([3, 224, 224]) 4\n",
      "SAMPLE SHAPE torch.Size([3, 36, 128])\n",
      "torch.Size([3, 224, 224]) torch.Size([3, 224, 224]) 4\n",
      "SAMPLE SHAPE torch.Size([3, 36, 128])\n",
      "torch.Size([3, 224, 224]) torch.Size([3, 224, 224]) 4\n",
      "SAMPLE SHAPE torch.Size([3, 36, 128])\n",
      "torch.Size([3, 224, 224]) torch.Size([3, 224, 224]) 4\n",
      "SAMPLE SHAPE torch.Size([3, 36, 128])\n",
      "torch.Size([3, 224, 224]) torch.Size([3, 224, 224]) 4\n",
      "SAMPLE SHAPE torch.Size([3, 36, 128])\n",
      "torch.Size([3, 224, 224]) torch.Size([3, 224, 224]) 4\n",
      "SAMPLE SHAPE torch.Size([3, 36, 128])\n",
      "torch.Size([3, 224, 224]) torch.Size([3, 224, 224]) 4\n",
      "SAMPLE SHAPE torch.Size([3, 36, 128])\n",
      "torch.Size([3, 224, 224]) torch.Size([3, 224, 224]) 4\n",
      "SAMPLE SHAPE torch.Size([3, 36, 128])\n",
      "torch.Size([3, 224, 224]) torch.Size([3, 224, 224]) 4\n",
      "SAMPLE SHAPE torch.Size([3, 36, 128])\n",
      "torch.Size([3, 224, 224]) torch.Size([3, 224, 224]) 4\n",
      "SAMPLE SHAPE torch.Size([3, 36, 128])\n",
      "torch.Size([3, 224, 224]) torch.Size([3, 224, 224]) 4\n",
      "SAMPLE SHAPE torch.Size([3, 36, 128])\n",
      "torch.Size([3, 224, 224]) torch.Size([3, 224, 224]) 4\n",
      "SAMPLE SHAPE torch.Size([3, 36, 128])\n",
      "torch.Size([3, 224, 224]) torch.Size([3, 224, 224]) 4\n",
      "SAMPLE SHAPE torch.Size([3, 36, 128])\n",
      "torch.Size([3, 224, 224]) torch.Size([3, 224, 224]) 4\n",
      "SAMPLE SHAPE torch.Size([3, 36, 128])\n",
      "torch.Size([3, 224, 224]) torch.Size([3, 224, 224]) 4\n",
      "SAMPLE SHAPE torch.Size([3, 36, 128])\n",
      "torch.Size([3, 224, 224]) torch.Size([3, 224, 224]) 4\n",
      "SAMPLE SHAPE torch.Size([3, 36, 128])\n",
      "torch.Size([3, 224, 224]) torch.Size([3, 224, 224]) 4\n",
      "SAMPLE SHAPE torch.Size([3, 36, 128])\n",
      "torch.Size([3, 224, 224]) torch.Size([3, 224, 224]) 4\n",
      "SAMPLE SHAPE torch.Size([3, 36, 128])\n",
      "torch.Size([3, 224, 224]) torch.Size([3, 224, 224]) 6\n",
      "SAMPLE SHAPE torch.Size([3, 36, 128])\n",
      "torch.Size([3, 224, 224]) torch.Size([3, 224, 224]) 6\n",
      "SAMPLE SHAPE torch.Size([3, 36, 128])\n",
      "torch.Size([3, 224, 224]) torch.Size([3, 224, 224]) 6\n",
      "SAMPLE SHAPE torch.Size([3, 36, 128])\n",
      "torch.Size([3, 224, 224]) torch.Size([3, 224, 224]) 6\n",
      "SAMPLE SHAPE torch.Size([3, 36, 128])\n",
      "torch.Size([3, 224, 224]) torch.Size([3, 224, 224]) 6\n",
      "SAMPLE SHAPE torch.Size([3, 36, 128])\n",
      "torch.Size([3, 224, 224]) torch.Size([3, 224, 224]) 6\n",
      "SAMPLE SHAPE torch.Size([3, 36, 128])\n",
      "torch.Size([3, 224, 224]) torch.Size([3, 224, 224]) 6\n",
      "SAMPLE SHAPE torch.Size([3, 36, 128])\n",
      "torch.Size([3, 224, 224]) torch.Size([3, 224, 224]) 6\n",
      "SAMPLE SHAPE torch.Size([3, 36, 128])\n",
      "torch.Size([3, 224, 224]) torch.Size([3, 224, 224]) 6\n",
      "SAMPLE SHAPE torch.Size([3, 36, 128])\n",
      "torch.Size([3, 224, 224]) torch.Size([3, 224, 224]) 6\n",
      "SAMPLE SHAPE torch.Size([3, 36, 128])\n",
      "torch.Size([3, 224, 224]) torch.Size([3, 224, 224]) 6\n",
      "SAMPLE SHAPE torch.Size([3, 36, 128])\n",
      "torch.Size([3, 224, 224]) torch.Size([3, 224, 224]) 6\n",
      "SAMPLE SHAPE torch.Size([3, 36, 128])\n",
      "torch.Size([3, 224, 224]) torch.Size([3, 224, 224]) 6\n",
      "SAMPLE SHAPE torch.Size([3, 36, 128])\n",
      "torch.Size([3, 224, 224]) torch.Size([3, 224, 224]) 6\n",
      "SAMPLE SHAPE torch.Size([3, 36, 128])\n",
      "torch.Size([3, 224, 224]) torch.Size([3, 224, 224]) 6\n",
      "SAMPLE SHAPE torch.Size([3, 36, 128])\n",
      "torch.Size([3, 224, 224]) torch.Size([3, 224, 224]) 6\n",
      "SAMPLE SHAPE torch.Size([3, 36, 128])\n",
      "torch.Size([3, 224, 224]) torch.Size([3, 224, 224]) 6\n",
      "SAMPLE SHAPE torch.Size([3, 36, 128])\n",
      "torch.Size([3, 224, 224]) torch.Size([3, 224, 224]) 6\n",
      "SAMPLE SHAPE torch.Size([3, 36, 128])\n",
      "torch.Size([3, 224, 224]) torch.Size([3, 224, 224]) 6\n",
      "SAMPLE SHAPE torch.Size([3, 36, 128])\n",
      "torch.Size([3, 224, 224]) torch.Size([3, 224, 224]) 6\n",
      "SAMPLE SHAPE torch.Size([3, 36, 128])\n",
      "torch.Size([3, 224, 224]) torch.Size([3, 224, 224]) 6\n",
      "SAMPLE SHAPE torch.Size([3, 36, 128])\n",
      "torch.Size([3, 224, 224]) torch.Size([3, 224, 224]) 6\n",
      "SAMPLE SHAPE torch.Size([3, 36, 128])\n",
      "torch.Size([3, 224, 224]) torch.Size([3, 224, 224]) 6\n",
      "SAMPLE SHAPE torch.Size([3, 36, 128])\n",
      "torch.Size([3, 224, 224]) torch.Size([3, 224, 224]) 6\n",
      "SAMPLE SHAPE torch.Size([3, 36, 128])\n",
      "torch.Size([3, 224, 224]) torch.Size([3, 224, 224]) 6\n",
      "SAMPLE SHAPE torch.Size([3, 36, 128])\n",
      "torch.Size([3, 224, 224]) torch.Size([3, 224, 224]) 6\n",
      "SAMPLE SHAPE torch.Size([3, 36, 128])\n",
      "torch.Size([3, 224, 224]) torch.Size([3, 224, 224]) 6\n",
      "SAMPLE SHAPE torch.Size([3, 36, 128])\n",
      "torch.Size([3, 224, 224]) torch.Size([3, 224, 224]) 1\n",
      "SAMPLE SHAPE torch.Size([3, 36, 128])\n",
      "torch.Size([3, 224, 224]) torch.Size([3, 224, 224]) 1\n",
      "SAMPLE SHAPE torch.Size([3, 36, 128])\n",
      "torch.Size([3, 224, 224]) torch.Size([3, 224, 224]) 1\n",
      "SAMPLE SHAPE torch.Size([3, 36, 128])\n",
      "torch.Size([3, 224, 224]) torch.Size([3, 224, 224]) 1\n",
      "SAMPLE SHAPE torch.Size([3, 36, 128])\n",
      "torch.Size([3, 224, 224]) torch.Size([3, 224, 224]) 1\n",
      "SAMPLE SHAPE torch.Size([3, 36, 128])\n",
      "torch.Size([3, 224, 224]) torch.Size([3, 224, 224]) 1\n",
      "SAMPLE SHAPE torch.Size([3, 36, 128])\n",
      "torch.Size([3, 224, 224]) torch.Size([3, 224, 224]) 1\n",
      "SAMPLE SHAPE torch.Size([3, 36, 128])\n",
      "torch.Size([3, 224, 224]) torch.Size([3, 224, 224]) 1\n",
      "SAMPLE SHAPE torch.Size([3, 36, 128])\n",
      "torch.Size([3, 224, 224]) torch.Size([3, 224, 224]) 1\n",
      "SAMPLE SHAPE torch.Size([3, 36, 128])\n",
      "torch.Size([3, 224, 224]) torch.Size([3, 224, 224]) 1\n",
      "SAMPLE SHAPE torch.Size([3, 36, 128])\n",
      "torch.Size([3, 224, 224]) torch.Size([3, 224, 224]) 1\n",
      "SAMPLE SHAPE torch.Size([3, 36, 128])\n",
      "torch.Size([3, 224, 224]) torch.Size([3, 224, 224]) 1\n",
      "SAMPLE SHAPE torch.Size([3, 36, 128])\n",
      "torch.Size([3, 224, 224]) torch.Size([3, 224, 224]) 1\n",
      "SAMPLE SHAPE torch.Size([3, 36, 128])\n",
      "torch.Size([3, 224, 224]) torch.Size([3, 224, 224]) 1\n",
      "SAMPLE SHAPE torch.Size([3, 36, 128])\n",
      "torch.Size([3, 224, 224]) torch.Size([3, 224, 224]) 1\n",
      "SAMPLE SHAPE torch.Size([3, 36, 128])\n",
      "torch.Size([3, 224, 224]) torch.Size([3, 224, 224]) 1\n",
      "SAMPLE SHAPE torch.Size([3, 36, 128])\n",
      "torch.Size([3, 224, 224]) torch.Size([3, 224, 224]) 1\n",
      "SAMPLE SHAPE torch.Size([3, 36, 128])\n",
      "torch.Size([3, 224, 224]) torch.Size([3, 224, 224]) 1\n",
      "SAMPLE SHAPE torch.Size([3, 36, 128])\n",
      "torch.Size([3, 224, 224]) torch.Size([3, 224, 224]) 1\n",
      "SAMPLE SHAPE torch.Size([3, 36, 128])\n",
      "torch.Size([3, 224, 224]) torch.Size([3, 224, 224]) 1\n",
      "SAMPLE SHAPE torch.Size([3, 36, 128])\n",
      "torch.Size([3, 224, 224]) torch.Size([3, 224, 224]) 1\n",
      "SAMPLE SHAPE torch.Size([3, 36, 128])\n",
      "torch.Size([3, 224, 224]) torch.Size([3, 224, 224]) 1\n"
     ]
    }
   ],
   "source": [
    "iterd = iter(train_dataset)\n",
    "for i in range(100):\n",
    "    nextval = next(iterd)\n",
    "    print(nextval[0].shape, nextval[1].shape, nextval[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms import Compose, ToPILImage, ToTensor, Normalize\n",
    "# Transform tensor to 224x224\n",
    "transform = Compose([\n",
    "    ToPILImage(),\n",
    "    ToTensor(),\n",
    "    Normalize(mean=[0.5], std=[0.5])\n",
    "])\n",
    "\n",
    "# Resize to 224x224\n",
    "train_dataset.transform = transform\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2433\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 1151 into shape (9,newaxis)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 18\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(elem)\n\u001b[0;32m     17\u001b[0m data \u001b[38;5;241m=\u001b[39m train_data\u001b[38;5;241m.\u001b[39miloc[elem,\u001b[38;5;241m1\u001b[39m:]\n\u001b[1;32m---> 18\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m9\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(y_val[train_y\u001b[38;5;241m.\u001b[39miloc[elem,\u001b[38;5;241m0\u001b[39m]])\n\u001b[0;32m     20\u001b[0m timeserie2image(data[:,:timestamps], \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimages/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtimestamps\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00my_val[train_y\u001b[38;5;241m.\u001b[39miloc[elem,\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00melem\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.png\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: cannot reshape array of size 1151 into shape (9,newaxis)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "y_val = {\n",
    "1: 'WALKING',\n",
    "2: 'WALKING_UPSTAIRS',\n",
    "3: 'WALKING_DOWNSTAIRS',\n",
    "4: 'SITTING',\n",
    "5: 'STANDING',\n",
    "6: 'LAYING'\n",
    "}\n",
    "timestamps = 128\n",
    "os.makedirs('images', exist_ok=True)\n",
    "random_elements = np.random.randint(0, train_data.shape[0], 10)\n",
    "for elem in random_elements:\n",
    "    print(elem)\n",
    "    data = train_data.iloc[elem,1:]\n",
    "    data = data.values.reshape(9, -1)\n",
    "    print(y_val[train_y.iloc[elem,0]])\n",
    "    timeserie2image(data[:,:timestamps], f'images/{timestamps}-{y_val[train_y.iloc[elem,0]]}-{elem}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36, 68)\n"
     ]
    }
   ],
   "source": [
    "timeserie2image(first_elem[:,:68], 'test.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1 27 25  3 15  8 19] [ 5  6  7 11 14 16 17 21 22 23 26 28 29 30]\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['1',   0,   1,   2,   3,   4,   5,   6,   7,   8,\n",
       "       ...\n",
       "       118, 119, 120, 121, 122, 123, 124, 125, 126, 127],\n",
       "      dtype='object', length=769)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_data = train_data[train_data.iloc[:,0].isin(users_for_validation)]\n",
    "train_data = train_data[train_data.iloc[:,0].isin(users_for_train)]\n",
    "# Remove users from the data\n",
    "train_data = train_data.iloc[:,1:]\n",
    "validation_data = validation_data.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering the labels\n",
    "train_y = train_y[train_y.iloc[:,0].isin(users_for_train)]\n",
    "validation_y = train_y[train_y.iloc[:,0].isin(users_for_validation)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [5]\n",
       "Index: []"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7351, 1), (7351, 128), (7351, 128), (7351, 1), (7351, 128))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users.shape, train_acc_x.shape, train_acc_y.shape, y_train.shape, train_total.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
